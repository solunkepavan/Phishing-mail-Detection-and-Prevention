# -*- coding: utf-8 -*-
"""Finetune T5 for Phishing Email Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kDMwtLNwNZwPHTbQC5EPigdEaoLm8qn7

### Install Libraries
"""

!pip install --upgrade transformers gradio==3.48.0 sentencepiece opendatasets pandas gdown

"""### Import Libraries"""

import pandas as pd
from sklearn.model_selection import train_test_split
from transformers import T5Tokenizer, T5ForSequenceClassification, AdamW
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import torch
import opendatasets as od
import pandas

"""### Import Data"""

!gdown --id 1cOohptk4-83tBadQvdkjGE8AZ9Tp3yuW -O documents.zip
!unzip -q documents.zip -d documents

#Import the Dataset
df= pd.read_csv("/content/documents/Phishing_Email.csv")
df.head()

# Check NAN values
print(df.isna().sum())
#Drop tha Na values
df = df.dropna()
print(df.isna().sum())

# Remove column name 'A'
df=df.drop(['Unnamed: 0'], axis=1)

df

"""### Split data"""

# Split the dataset into training and testing sets
train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)

train_data

# Define a custom dataset class
class EmailDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts.iloc[idx])
        label = int(self.labels.iloc[idx] == 'Phishing Email')
        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

"""### Load Base LLM model & tokenizer"""

# Instantiate the T5 tokenizer and model
tokenizer = T5Tokenizer.from_pretrained('t5-small')
model = T5ForSequenceClassification.from_pretrained('t5-small', num_labels=2)  # binary classification

"""### Training(Finetunning) Process"""

# Create datasets and dataloaders
train_dataset = EmailDataset(train_data['Email Text'], train_data['Email Type'], tokenizer)
test_dataset = EmailDataset(test_data['Email Text'], test_data['Email Type'], tokenizer)

train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)

# Set up optimizer and training parameters
optimizer = AdamW(model.parameters(), lr=2e-5)
num_epochs = 1

# Training loop
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

for epoch in range(num_epochs):
    model.train()
    total_loss = 0

    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}'):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        total_loss += loss.item()

        loss.backward()
        optimizer.step()

    average_loss = total_loss / len(train_dataloader)
    print(f'Average training loss for Epoch {epoch + 1}: {average_loss}')

"""### Evaluation of finetunned model"""

# Evaluation
model.eval()
all_labels = []
all_predictions = []

with torch.no_grad():
    for batch in tqdm(test_dataloader, desc='Evaluating'):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        outputs = model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=1).cpu().numpy()

        all_labels.extend(labels.cpu().numpy())
        all_predictions.extend(predictions)

from sklearn.metrics import accuracy_score, classification_report
# Calculate accuracy and other metrics
accuracy = accuracy_score(all_labels, all_predictions)
report = classification_report(all_labels, all_predictions)

print(f"Accuracy: {accuracy}")
print("Classification Report:\n", report)

"""### Save finetunned model"""

# Save the fine-tuned model
model.save_pretrained('fine_tuned_t5_model')
tokenizer.save_pretrained('fine_tuned_t5_model')

"""### Test finetunned model for custom input"""

# Load the fine-tuned model and tokenizer
loaded_model = T5ForSequenceClassification.from_pretrained('fine_tuned_t5_model')
loaded_tokenizer = T5Tokenizer.from_pretrained('fine_tuned_t5_model')

# Example usage for prediction
sample_input = """
URL: http://www.newsisfree.com/click/-5,8304313,1717/
Date: 2002-09-27T08:51:29+01:00[IMG: http://www.newsisfree.com/Images/fark/cbc.ca.gif ([CBC])]

"""

def predict_email_type(email_text, model, tokenizer):
    inputs = tokenizer(email_text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)

    logits = outputs.logits
    predicted_class = torch.argmax(logits, dim=1).item()

    return "Phishing Email" if predicted_class == 1 else "Safe Email"

predicted_type = predict_email_type(sample_input, loaded_model, loaded_tokenizer)
print(f"Predicted Email Type: {predicted_type}")

"""### front-end using gradio(optional)"""

# Define the prediction function
import gradio as gr

def predict_email_type(email_text):
    inputs = loaded_tokenizer(email_text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = loaded_model(**inputs)

    logits = outputs.logits
    predicted_class = torch.argmax(logits, dim=1).item()

    return "Phishing Email" if predicted_class == 1 else "Safe Email"

# Create Gradio Interface
iface = gr.Interface(
    fn=predict_email_type,
    inputs=gr.Textbox(),
    outputs=gr.Textbox(),
    live=True,
    title="Email Type Predictor",
    description="Enter an email text and get the predicted email type.",
)

# Launch the interface
iface.launch()

